{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blinks\n",
    "\n",
    "In this notebook, the analysis on the blinks is done.\n",
    "\n",
    "First, all the dependencies are imported and some functions are defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from sys import platform\n",
    "\n",
    "#all the functions are in this module\n",
    "from EEGAnalysis import *\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newSession(GPU=0, CPU=8, randomSeed = 8):\n",
    "    #delete previous model and set up session. Also resets the random seed.\n",
    "    np.random.seed(randomSeed)\n",
    "    tf.keras.backend.clear_session()\n",
    "    config = tf.ConfigProto(device_count={'GPU':GPU, 'CPU':CPU})\n",
    "    config.gpu_options.allow_growth = True\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "    tf.keras.backend.set_session(tf.Session(config=config))\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the file is imported and processed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the file\n",
    "filename = 'EEGdata/blinks_2019.03.25_14.56.23.edf'\n",
    "rate = 256\n",
    "\n",
    "#readEDF-function in python module EEGAnalysis\n",
    "EEGData, markerData = readEDF(filename, CQ = True, markers = True, motion = False, powerLineHumFilter = True)\n",
    "xTrain, yTrain, xTest, yTest = None, None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['blank', 'blink']\n",
    "events = createEvents(markerData, np.array([4, 5]))\n",
    "\n",
    "#create Epochs\n",
    "tmin = -0.2   # set time around events to create Epochs\n",
    "tmax = 0.8\n",
    "\n",
    "#parameters for the creation of the Epochs\n",
    "CQ = True\n",
    "normalize = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done making training/test-sets, shapes:  (99, 257, 14) (99, 2) (12, 257, 14) (12, 2)\n"
     ]
    }
   ],
   "source": [
    "(xTrain, yTrain),(xTest, yTest) = createEpochs(EEGData, events, tmin, tmax, CQ = CQ, normalize = normalize, verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're defining and training the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 train samples\n",
      "12 test samples\n",
      "WARNING:tensorflow:From //anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From //anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 3598)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                230336    \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8320      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 258       \n",
      "=================================================================\n",
      "Total params: 238,914\n",
      "Trainable params: 238,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "0300-Blinks-Fl-D64-DO=0.3-D128-DO=0.3-D2-Adam-LR=1e-03\n",
      "WARNING:tensorflow:From //anaconda/envs/tf/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "12/12 [==============================] - 0s 86us/sample - loss: 1.5527 - acc: 0.8333 - f1: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blank</th>\n",
       "      <th>blink</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>blank</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blink</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blank  blink\n",
       "blank      1      2\n",
       "blink      0      9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss : 1.55\n",
      "Test acc : 0.83\n",
      "Test f1 : 0.83\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "verbose = 0\n",
    "batchSizeGlobal = 32\n",
    "epochs = 30 #number of times the network is trained on the entire set.\n",
    "loadPreviousModels = False #loads the checkpoints\n",
    "run = '0300-Blinks-'\n",
    "LR = 1e-3\n",
    "loss = 'binary_crossentropy'\n",
    "metrics = ['accuracy', f1]\n",
    "patience = 10\n",
    "min_delta = 1e-5\n",
    "\n",
    "#prevent naive model\n",
    "classWeight = {}\n",
    "for i in range(len(classes)):\n",
    "    classWeight[i] = unpackClasses(yTrain).tolist().count(i)\n",
    "\n",
    "newSession()\n",
    "\n",
    "print(xTrain.shape[0], 'train samples')\n",
    "print(xTest.shape[0], 'test samples')\n",
    "\n",
    "#build model\n",
    "initializer = None\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape= (xTrain.shape[1:])))\n",
    "model.add(Dense(64, activation='relu',\n",
    "                kernel_initializer = initializer))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(rate = 0.3))\n",
    "model.add(Dense(len(yTest[0]), activation='sigmoid'))\n",
    "model.summary()\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(lr=LR)#, decay=1.5)#rho=rho, epsilon=epsilon,\n",
    "model.compile(optimizer=optimizer, loss=loss,  metrics=metrics)\n",
    "\n",
    "#make filepaths\n",
    "networkname = run + makeNameModel(model)\n",
    "time = datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
    "logDir = './blinks/logs/' + networkname + time\n",
    "modelFile = './blinks/logs/' + networkname + '.hdf5'\n",
    "if platform.count('Windows'):\n",
    "    logDir = os.getcwd() + logDir\n",
    "    modelFile = os.getcwd() + modelFile\n",
    "    if not loadPreviousModels:\n",
    "        os.makedirs(logDir)\n",
    "\n",
    "if loadPreviousModels:\n",
    "    model.load_weights(modelFile)\n",
    "\n",
    "# prepare callbacks and checkpoint learning\n",
    "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logDir, histogram_freq=0,\n",
    "                            write_graph=True, write_images=False, write_grads = True, update_freq = 'epoch')\n",
    "checkpoint = tf.keras.callbacks.ModelCheckpoint(modelFile, monitor='val_loss', mode = 'min', period=5, save_best_only=False)\n",
    "earlyStopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', mode = 'min', patience=patience, min_delta = min_delta)\n",
    "histories = Histories()\n",
    "\n",
    "print(networkname)\n",
    "\n",
    "#batch size\n",
    "batch_size = 32\n",
    "\n",
    "model.fit(xTrain, yTrain, epochs=epochs, batch_size=batch_size, verbose = verbose,\n",
    "          callbacks = [tensorboard, checkpoint, earlyStopping, histories],\n",
    "          validation_data=(xTest, yTest), class_weight=classWeight)\n",
    "\n",
    "trainResult = np.array([histories.loss, histories.acc, histories.f1])\n",
    "testResult = np.array([histories.val_loss, histories.val_acc, histories.val_f1])\n",
    "\n",
    "score = model.evaluate(xTest, yTest, verbose=1)\n",
    "\n",
    "y_pred = model.predict_classes(xTest)\n",
    "y_true = unpackClasses(yTest)\n",
    "conf_matrix_test = confusion_matrix(y_true, y_pred)\n",
    "dispMat(conf_matrix_test, names = classes)\n",
    "\n",
    "temp = 0\n",
    "for i in model.metrics_names:\n",
    "    print('Test', str(i), ':', round(score[temp], 2))\n",
    "    temp += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#log the results in a .npy file\n",
    "logDir = os.getcwd() + '/blinks/logsNpy'\n",
    "trainFile = logDir + '/' + networkname + '-train'\n",
    "testFile = logDir + '/' +  networkname + '-test'\n",
    "\n",
    "try:\n",
    "    np.save(trainFile, trainResult)\n",
    "    np.save(testFile, testResult)\n",
    "except:\n",
    "    os.makedirs(logDir)\n",
    "    np.save(trainFile, trainResult)\n",
    "    np.save(testFile, testResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
